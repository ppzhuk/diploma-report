%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Разработка}
\label{chap:dev}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Обзор этапов подхода}
\label{sec:overview}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Этап 1 --- подготовка обращений к отображению в ЧЗВ. Сырые данные содержат много шума: HTML разметка, заголовки электронной почты (<<01 июля 2001 г., 10:10 пользователь ... написал:>>), приветствия, благодарности и так далее. Этот шум заметно влияет на алгоритм. Для повышения качества результатов применяется ряд эвристик предобработки, которые значительно доработаны в сравнение со статьей~\cite{original}. При этом также фильтруются обращения, которые заведомо не могут содержать вопроса или ответа. 

Этап 2 --- определение кластеров связанных обращений (в дальнейшем --- тем) используется скрытое размещение Дирихле. LDA описывает каждую тему с помощью мешка слов (наиболее характерных терминов) и для каждого обращения определяет вероятностное распределение по темам. Затем каждому обращению сопоставляется тема с наибольшей вероятностью. После чего темы проходят через фильтр, с целью удаления незначимых с точки зрения ЧЗВ тем.

Этап 3 --- формирование ВОП. Для каждого комментария в рамках обращения считается метрика близости между текстом комментария и соответствующей темой. На основе этой метрики определяются хорошо сформулированные вопросы и релевантные ответы на них.

Стоит отметить, что хотя темематическое моделирование и позволяет определить схожие по терминологии вопросы, которые фактичечски являются часто задаваемыми, алгоритм не ограничивается только этим и позволяет находить редкие ВОП, если они хорошо сформулированы и имеют корректный ответ. При этом большее внимание в работе уделялось поиску качественных ВОП (точность), чем поиску всех возможных ВОП (полнота). Основная мотивация такого решения заключается в желании сократить до минимума ручную часть алгоритма --- валидацию и редактирование ВОП.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Предобработка данных}
\label{sec:dev}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Исходные данные представляют собой 6500 обращений, собранных из различных каналов поступления обращений с помощью системы автоматизации запросов клиентов Zendesk\footnote{www.zendesk.com}. Каждое обращение содержат ряд метаданных. В то время как использование метаданных ограничивает область применения алгоритма, это позволяет повысить его качество. В данной работе использовалась метаинформация, широко распространненная для данных такого рода: статус обращения и авторство комментария.

Мы предполагаем, что ответ на вопрос содержится в одном комментарии и не пытаемся объединить несколько комментариев для создания ответа. Для анализа использовались только обращения на английском языке.

Эвристики предобработки делятся на 2 категории: эвристики отображения и эвристики тематического моделирования. Первые предназначены для приведения обращений к виду, максимально близкому к виду ЧЗВ, вторые --- применяются поверх первых и создают отдельное представление, используемое в LDA.

Из входных данных были отфильтрованы обращения только со статусом "закрыто" и "выполнено". Данные статусы говорят о том, что обращения  имеют окончательный набор комментариев, в то время как другие обращения еще могут находиться в активном обсуждении.

\subsection{Эвристики отображения}
\label{subsec:lnfheur}

\textit{Эвристика 1 (специфичные регулярные выражения): }  данная эвристика направлена на удаление фрагментов, зависящих от предметной области или используемого програмного обеспечения. Например: информация, добавляемая системой управления обращениями; шаблоны оформления обращений через веб-форму, содержащие дополнительные поля (имя, e-mail, компания); и так далее.

\textit{Эвристика 2 (удаление цитат электронной почты):} 33\% обращений созданы через электронную почту. Комментарии в таких обращениях часто цитируют предыдущее сообщение. Для удаления цитат использовалась самостоятельно разработанная библиотека email-parser\footnote{https://github.com/JetBrains/email-parser}.

\textit{Эвристика 3 (удаление общих суффиксов):} большинство пользователей, как правило, имеют подпись, которая добавляется в конец каждого отправленного ими сообщения. Для удаления таких подписей предлагается следующее:
 \begin{itemize}
\item Для всех комментариев в исходных данных попарно посчитать общий суффикс;
\item У каждого комментария удалить суффикс максимальной длины;
\end{itemize}
Cуффикс определяется построчно, что позволяет избежать частичного удаления абзацев с полезной информацией.

\textit{Эвристика 4 (короткие абзацы):} многие сообщения начинаются со слов приветсвия и заканчиваются словами благодарности. Как правило, эти фрагменты выделены в отдельные абзацы (отделены символом новой строки) и значительно короче основной части сообщения (20-25 символов против 300-500). Данная эвристика удаляет (при наличии) один короткий начальный абзац и все короткие конечные абзацы. Абзац является коротким, если он состоит из 3 или меньше слов. Это число было определено эмпирически. Дополнительно этот шаг позволяет удалить фрагменты подписи, оставшиеся после эвристики 3.

\textit{Эвристика 5 (частые предложения):} данная эвристика была взята из статьи \cite{original} и говорит о том, что предложения, встречающиеся на всем наборе обращений более 15 раз, не содержат информации, специфичной для конкретного вопроса. Стоит отметить, что учитывание предложений, состоящих из одного слова, или игнорирование регистра текста приводит к частичному удалению предложений и, как следствие, ухудшению внешнего вида ВОП.

Как результат применения описанных выше эвристик текст комментариев часто может начинаться с нижнего регистра (ввиду удаления приветствий) и содержать лишние пустые строки, что снижает читаемость. Данные недостатки следует исправить, так как именно в таком виде ВОП будут показываться экспертам.

\subsection{Эвристики тематического моделирования}
\label{subsec:ldaheur}

Эвристики из данной группы применяются с целью повышения качества LDA. Поскольку при этом теряется часть информации, необходимой для отображения ЧЗВ, две версии каждого комментария должно быть сохранено, как показано в таблице \ref{heuristics_table}.

\textit{Эвристика 6 (регулярные выражения):} пользовательские данные ухудшают качество LDA. Например, тема, включающая в себя имя некоторого пользователя, будет содержать обращения, в которых часто встречается это имя, несмотря на то, что сами обращения могут относиться к разным подсистемам. На этом этапе предлагается удалять: унифицированные идентификаторы ресурса (URI) и пути, адреса электронной почты и названия сайтов (www.mysite.com).

\textit{Эвристика 7 (удаление длинных абзацов):} абзацы естественной речи для ИТ-дискуссий редко превышают 800 символов, в то время как длина машинно сгенерированного текста (логи, трассировки, код) часто больше этого значения.

\textit{Эвристика 8 (абзацы с пунктуацией):} было установлено, что абзацы длиной больше 200 символов и содержащие более 6\% символов пунктуации также являются машинно сгенерированными. Ограничение на минимальную длину абзаца позволяет избежать ложных срабатываний. В качестве символов пунктуации использовались следующие символы:

\vspace{2mm}

\noindent \textit{'`-=|\/*+,;:()\{\}[]<>\%\$@\&\_}

\vspace{2mm}

\textit{Эвристика 9 (удаление стоп-слов):} удаляются наиболее частые слова английского языка, которые не помогают в определении темы в виду своего общего назначения. К ним стоит добавить слова, часто используемые в анализируемой области ('java' или 'class' для обсуждения разработки на Java).
\begin{table}[!ht]
\caption{Эффект применения эвристик}
\label{heuristics_table}
\centering
\begin{tabular}{|c|c|}
\hline
Версия для ЧЗВ & Версия для LDA \\
\hline
\parbox[t]{4cm}{I want to configure youtrack over SSL but
not able to find any solution or article on the subject} & \parbox[t]{4cm}{configure SSL solution article subject}\\
\hline
\end{tabular}
\end{table}
\subsection{Фильтрация обращений}
\label{subsec:ticketfilter}

После применения эвристик некоторые из комментариев могут оказаться пустыми, в то время как другие могут не содержать ответа от технического специалиста. Из таких обращений не удастся извлечь ВОП. Воспользуемся метаинформацией об авторстве и отфильтруем обращения, имеющие не пустой первый комментарий (в версии для LDA) и не менее одного не пустого комментария от сотрудника технической поддержки.

Обращения, содержащие длинную нить обсуждения (более 6 комментариев), вероятно, имеют одну из следующих проблем: вопрос плохо сформулирован, вопрос слишком специфичен, ответ недостаточно полон и содержится в нескольких комментариях. Такие обращения необходимо удалить.

Спицифичные для предметной области обращения, например: обращение закрытое по причине слияния с другим обращением, и так далее --- также необходимо удалить.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Тематическое моделирование}
\label{sec:topicmodeling}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Тематическое моделирование \cite{TM} позволяет (а) сгруппировать схожие обращения по темам (например, одна тема может касаться почтовой интеграции, а другая --- вопросов о продлении подписки для пользователей), (б) охарактеризовать каждую тему списком терминов --- мешком слов.

\subsection{Скрытое размещение Дирихле}
\label{subsec:lda}

В работе использовался метод скрытого размещения Дирихле и его реализация на Java \cite{MALLET}. LDA работает с любыми текстовыми документами, поэтому далее будет использоваться термин 'документ' для описания обращения, как совокупности его комментариев.

LDA --- это вероятностная тематическая модель, не требующая размеченных данных для обучения, однако требуещая указания количества моделируемых тем. LDA описывает каждую тему $t$, как вероятностное распределение по всем словам из входных данных ($\phi_t$). Каждый документ $d$ описывается вероятностным распределением по темам ($\theta_d$). Цель LDA - максимизировать функцию (1) путем оптимизации $\phi$ и $\theta$:
$$
P(\theta, \phi)=\prod_{t=1}^{T}P(\phi_t)\prod_{d=1}^{D}P(\theta_d)\prod_{w=1}^{W_d}P(Z_{d,w}|\theta_d)P(N_{t,w}|\phi_t) \eqno(1)
$$
где $T$ --- количество тем, $D$ --- количество документов, $W_d$ --- количество различных слов в документе $d$, $Z_{d,w}$ --- определяет принадлежность слова $w$ к документу $d$ и $N_{t,w}$ --- принадлежность слова $w$ к теме $t$.

Распределения $\phi$ и $\theta$ в свою очередь зависят от гиперпараметров $\alpha$ и $\beta$ соответственно. Реализация LDA в \cite{MALLET} поддерживает автоматическую оптимизацию этих параметров с использованием сэмплирования по Гиббсу \cite{gibbs}. Программисту остается лишь указать количество тем.

Определение количества тем --- нетривиальная задача. Используемая метрика - перплексия \cite{LDA}, показывает сходство между терминами документов и их темой (меньше - лучше), но не отражает семантическую связь, поэтому так важен этап экспертной оценки. Тем не менее, перплексия позволяет определить минимальное число тем, при котором обращения начинают разделяться на четко выраженные подтемы. Критерием является значительное замедление скорости падения перплексии с ростом числа тем. Раздел \ref{sec5}-\ref{sec5-c} показывает как можно избавиться от расфокусированных тем, поэтому точное определение количества тем не требуется. Основываясь на перплексии, для построения тематической модели было выбрано количество тем, равное 250.

В результате тематического моделирования для каждого документа определяется вероятностное распределение по темам $\theta_{d,t}$. Мы сопоставляем каждому обращению одну тему --- тему с максимальной вероятностью. Однако, если для обращения $d$ вероятность каждой темы $\theta_{d,t}<0.25$, то такое обращение не имеет четко выраженной темы и для него не будет определяться ВОП.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Формирование пар вопрос-ответ}
\label{sec:qaforming}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Процесс получения ЧЗВ из смоделированных тем состоит из трех шагов: фильтрация неинформативных тем, определение пар вопрос-ответ, удаление расфокусированных тем.

\subsection{Дополнительная фильтрация}
\label{subsec:topicfilter}

Данный этап не обязателен и предполагает некоторые априорные знания о данных, а также то, что алгоритм уже запускался ранее. Используемые в работе данные (обращения в техническую поддержку) могут содержать большое количество типичных, повторяющихся обращений с шаблонными ответами (просьбы о сбросе пароля; вопросы о недоступности сервиса и так далее). Такие обращения являются частыми, но не несут полезной информации для ЧЗВ.

После построения тематической модели можно найти мешки слов для таких тем. Следует оставить 10 наиболее значимых слов для каждой из них. При последующих запусках LDA удаляются темы, для которых выполняется условие: хотя бы половина из топ-10 слов темы совпадают с одной из фильтруемых тем. Темы проверяются на частичное совпадение, поскольку LDA недетерминирован и мешки слов могут незначительно отличаться от запуска к запуску.

Данный фильтр позволяет избавиться от шаблонных ВОП, однако может негативно влиять на метрики качества (см. раздел \ref{sec6}), поскольку удаляемые таким образом темы  четко выражены и содержат большое количество обращений.

\subsection{Определение вопросов и ответов}
\label{subsec:findqa}

Для определения вопросов и ответов для каждого комментария вычисляется метрика близости с соответствующей темой. Для этого использовалось косинусное расстояние \cite{cosine}: 
$$
\cos(e, t)=\frac{\sum_{i=1}^nt_ie_i}{\sum_{i=1}^n(t_i)^2\sum_{i=1}^n(e_i)^2}\eqno(2)
$$
где $t$ - вектор, соответствущий мешку слов темы, $e$ - вектор, соответствующий словам комментария в представлении для LDA. Чем больше значение косинуса, тем сильнее комментарий связан с темой.

Комментарий выбирается в качестве \textit{вопроса} при выполнении трех условий: (a) это первый комментарий в обращении; (б) косинус комментария и темы ($\cos(Q,T)$) выше порога 0.15; (в) длина комментария не превышает 1000 символов (более длинный текст комментария говорит о слишком специфичном для конкретного пользователя вопросе).

Условия выбора комментария в качестве \textit{ответа}: (а) это не первый комментарий в обращении; (б) не является комменатрием инициатора обращения; (в) косинусное расстояние с темой ($\cos(A,T)$) выше порога 0.15 и максимально среди других кандитатов на ответ.

Обращения в службу поддержки, типично представляют собой диалог с итеративным уточнением деталей, предоставлением дополнительной информации и попытками дать окончательныый ответ. В качестве вопроса выбирается только инициирующий комментарий, поскольку все последующие комментарии пользователя не будут содержать полной информации о проблеме. Ответом считается комментарий сотрудника технической поддержки, наиболее совпадающий с темой по используемым терминам. Таким образом, обеспечивается сходство терминологии между вопросом и ответом для найденных ВОП.

\subsection{Удаление расфокусированных тем}
\label{subsec:deleteunfocusedtopics}

Ввиду отсутствия возможности точно определить моделируемое число тем (см. \ref{sec4}-\ref{sec4LDA}) возможны случаи, когда реальное количество тем будет меньше или больше смоделированного. В первом случае полученные после LDA темы будут слишком общими, что приведет к большим различиям между терминологий темы и приналежащими ей обращениями и, как следствие, пониженному количеству и качеству найденных ВОП. Во втором --- создадутся фантомные темы, терминология которых будет плохо совпадать с реальными данными. Удалим такие расфокусированные темы за счет введения минимальной доли ВОП (3) со значением 0,1. 
$$
\frac{|QAPairs|}{|tickets|}>threshold\eqno(3)
$$
Образованные ВОП упорядочиваются (в рамках каждой темы или глобально) с использованием гармонического среднего между $\cos(Q,T)$ и $\cos(A,T)$. Гармоническое среднее (4) для получения высокого значения требует, чтобы все составляющие были высоки, таким образом, гарантируется, что и вопрос, и ответ имеют высокое качество.
$$
H = \frac{n}{\sum_{i=1}^n\frac{1}{x_i}}\eqno(4)
$$
После этого ВОП передаются эксперту для валидации и редактирования перед публикацией. 

